services:
  qdrant:
    image: qdrant/qdrant
    ports:
      - 6333:6333
      - 6334:6334
    volumes:
      - qdrant_storage:/qdrant/storage

    environment:
      - QDRANT_ALLOW_RECOVERY_MODE=true
    networks:
      - ollama-docker

  # ollama:
  #   image: docker.io/ollama/ollama:latest
  #   ports:
  #     - 7869:11434
  #   volumes:
  #     - .:/code
  #     - ./ollama/ollama:/root/.ollama
  #   container_name: ollama-container
  #   pull_policy: always
  #   tty: true
  #   restart: always
  #   environment:
  #     - OLLAMA_KEEP_ALIVE=24h
  #     - OLLAMA_HOST=0.0.0.0
  #   networks:
  #     - ollama-docker
  ollama:
    volumes:
      - ./ollama/ollama:/root/.ollama
    container_name: ollama_container
    pull_policy: always
    tty: true
    restart: unless-stopped
    image: docker.io/ollama/ollama:latest
    ports:
      - 7869:11434
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    networks:
      - ollama-docker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]


  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    volumes:
      - ./src:/app/src
      - ./data:/app/data     
      - ./uploads:/app/uploads 
      - ./report:/app/report
      - ./model_cache:/root/.cache 



    depends_on:
      qdrant:
        condition: service_started
      ollama:
        condition: service_started
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - QDRANT_HOST=http://qdrant:6333
    networks:
      - ollama-docker

volumes:
  qdrant_storage:
    driver: local

networks:
  ollama-docker:
    driver: bridge
